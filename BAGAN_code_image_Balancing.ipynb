{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Haritha oru loosu\n"
     ]
    }
   ],
   "source": [
    "print(\"Haritha oru loosu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.keras.layers import Input, Reshape, Dense, Dropout, \\\n",
    "    Activation, LeakyReLU, Conv2D, Conv2DTranspose, Embedding, \\\n",
    "    Concatenate, multiply, Flatten, BatchNormalization, UpSampling2D\n",
    "from tensorflow.keras.initializers import glorot_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator as IDG\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q_/0dw87v091v5cpmzqgt328knr0000gn/T/ipykernel_82736/3288189131.py:31: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  y_train[np.where(y_train=='0')]=0\n",
      "/var/folders/q_/0dw87v091v5cpmzqgt328knr0000gn/T/ipykernel_82736/3288189131.py:32: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  y_train[np.where(y_train=='1')]=1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_train = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/train'\n",
    "data_val = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/val'\n",
    "data_test = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/test'\n",
    "\n",
    "def load_images_from_path(path):\n",
    "    X = []\n",
    "    y = []\n",
    "    for label in os.listdir(path):\n",
    "        label_path = os.path.join(path, label)\n",
    "        for filename in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            img = cv2.resize(img, (64, 64)).reshape((64, 64, 3))  # Resize the image to desired shape\n",
    "            img = img.astype('float32') / 127.5  # Normalize pixel values to [0, 1]\n",
    "            X.append(img)\n",
    "            y.append(label)\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_train, y_train = load_images_from_path(data_train)\n",
    "X_val, y_val = load_images_from_path(data_val)\n",
    "X_test, y_test = load_images_from_path(data_test)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "#y_train = np.where(y_train == '0', 0, 1)\n",
    "#y_test = np.where(y_test == '0', 0, 1)\n",
    "y_train[np.where(y_train=='0')]=0\n",
    "y_train[np.where(y_train=='1')]=1\n",
    "# Perform label encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.int64'>\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(y_train[0]))\n",
    "print(y_train[1])\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: 0: 1341\n",
      "1: 3875\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train = np.concatenate([X_train, X_val])\n",
    "y_train = np.concatenate([y_train, y_val])\n",
    "\n",
    "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n",
    "print(\"Class distribution: {}: {}\\n{}: {}\".format(unique_labels[0], label_counts[0], unique_labels[1], label_counts[1]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "label_to_downsample = 0\n",
    "num_images_to_keep = 450\n",
    "\n",
    "indices_to_keep = np.where(X_train[:, -1] == label_to_downsample)[0]\n",
    "np.random.shuffle(indices_to_keep)\n",
    "indices_to_keep = indices_to_keep[:num_images_to_keep]\n",
    "print(indices_to_keep)\n",
    "X_train = X_train[indices_to_keep]\n",
    "y_train = y_train[indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] []\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1:10], y_train[1:10])\n",
    "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4288, 1)\n",
      "label\n",
      "PNEUMONIA    3883\n",
      "NORMAL        405\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_train = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/train'\n",
    "data_val = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/val'\n",
    "data_test = '/Users/haritha/Desktop/Spring23/DataMiningProject/chest_xray/test'\n",
    "\n",
    "train_filepaths = []\n",
    "train_labels = []\n",
    "test_filepaths = []\n",
    "test_labels = []\n",
    "for class_dir in os.listdir(data_train):\n",
    "    class_path = os.path.join(data_train, class_dir)\n",
    "    for filepath in os.listdir(class_path):\n",
    "        train_filepaths.append(os.path.join(class_path, filepath))\n",
    "        train_labels.append(class_dir)\n",
    "for class_dir in os.listdir(data_val):\n",
    "    class_path = os.path.join(data_val, class_dir)\n",
    "    for filepath in os.listdir(class_path):\n",
    "        train_filepaths.append(os.path.join(class_path, filepath))\n",
    "        train_labels.append(class_dir)\n",
    "df_train = pd.DataFrame({'image_path': train_filepaths, 'label': train_labels})\n",
    "\n",
    "df_train_downsampled = pd.concat([\n",
    "    df_train[df_train['label'] == 'NORMAL'].sample(frac=0.3, random_state=42),\n",
    "    df_train[df_train['label'] == 'PNEUMONIA']\n",
    "], ignore_index=True)\n",
    "\n",
    "for class_dir in os.listdir(data_test):\n",
    "    class_path = os.path.join(data_test, class_dir)\n",
    "    for filepath in os.listdir(class_path):\n",
    "        test_filepaths.append(os.path.join(class_path, filepath))\n",
    "        test_labels.append(class_dir)\n",
    "df_test = pd.DataFrame({'image_path': test_filepaths, 'label': test_labels})\n",
    "\n",
    "'''y_train = df_train_downsampled['label']\n",
    "X_train = df_train_downsampled.drop(df_train_downsampled.columns[1], axis=1)\n",
    "y_test = df_test['label']\n",
    "X_test = df_test.drop(df_test.columns[1], axis=1)\n",
    "print(X_train.shape)\n",
    "print(y_train.value_counts())'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4288 validated image filenames belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = IDG()\n",
    "test_datagen=IDG()\n",
    "train_filepaths = []\n",
    "train_labels = []\n",
    "BATCH_SIZE = 128\n",
    "img_size = (224, 224, 3)\n",
    "n_classes = 2\n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=df_train_downsampled,\n",
    "    x_col='image_path',\n",
    "    y_col=\"label\",\n",
    "    target_size=img_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_gen = test_datagen.flow_from_directory(\n",
    "    data_test,\n",
    "    target_size=img_size,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary',\n",
    "    shuffle=False,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=0.0002, beta_1=0.5, beta_2=0.9)\n",
    "latent_dim=128\n",
    "# trainRatio === times(Train D) / times(Train G)\n",
    "trainRatio = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def decoder():\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    noise_le = Input((latent_dim,))\n",
    "\n",
    "    x = Dense(4*4*448)(noise_le)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Reshape((4, 4, 448))(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters=224,\n",
    "                        kernel_size=(4, 4),\n",
    "                        strides=(2, 2),\n",
    "                        padding='same',\n",
    "                        kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    ## Size: 16 x 16 x 128\n",
    "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    x = UpSampling2D(size=(2, 2))(x)\n",
    "    ## Size: 32 x 32 x 64\n",
    "    x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    ## Size: 64 x 64 x 3\n",
    "    generated = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh', kernel_initializer=init)(x)\n",
    "\n",
    "\n",
    "    generator = Model(inputs=noise_le, outputs=generated)\n",
    "    return generator'''\n",
    "img_size = X_train[0].shape\n",
    "def decoder():\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    noise_le = Input((latent_dim,))\n",
    "\n",
    "    x = Dense(4*4*256)(noise_le)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "\n",
    "    x = Reshape((4, 4, 256))(x)\n",
    "\n",
    "    x = Conv2DTranspose(filters=128,\n",
    "                        kernel_size=(4, 4),\n",
    "                        strides=(2, 2),\n",
    "                        padding='same',\n",
    "                        kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    ## Size: 16 x 16 x 128\n",
    "    x = Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    ## Size: 32 x 32 x 64\n",
    "    x = Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "\n",
    "    ## Size: 64 x 64 x 3\n",
    "    generated = Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh', kernel_initializer=init)(x)\n",
    "\n",
    "\n",
    "    generator = Model(inputs=noise_le, outputs=generated)\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def encoder():\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    img = Input(img_size)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(img)\n",
    "    # x = LayerNormalization()(x) # It is not suggested to use BN in Discriminator of WGAN\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(224, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    feature = Flatten()(x)\n",
    "\n",
    "    feature = Dense(latent_dim)(feature)\n",
    "    out = LeakyReLU(0.2)(feature)\n",
    "\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "    return model'''\n",
    "\n",
    "def encoder():\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    img = Input(img_size)\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(img)\n",
    "    # x = LayerNormalization()(x) # It is not suggested to use BN in Discriminator of WGAN\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    # 4 x 4 x 256\n",
    "    feature = Flatten()(x)\n",
    "\n",
    "    feature = Dense(latent_dim)(feature)\n",
    "    out = LeakyReLU(0.2)(feature)\n",
    "\n",
    "    model = Model(inputs=img, outputs=out)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_labeled_latent():\n",
    "    # # weight initialization\n",
    "    # init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    label = Input((1,), dtype='int32')\n",
    "    noise = Input((latent_dim,))\n",
    "    # ne = Dense(256)(noise)\n",
    "    # ne = LeakyReLU(0.2)(ne)\n",
    "\n",
    "    le = Flatten()(Embedding(n_classes, latent_dim)(label))\n",
    "    # le = Dense(256)(le)\n",
    "    # le = LeakyReLU(0.2)(le)\n",
    "\n",
    "    noise_le = multiply([noise, le])\n",
    "    # noise_le = Dense(latent_dim)(noise_le)\n",
    "\n",
    "    model = Model([noise, label], noise_le)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haritha/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/keras/initializers/initializers.py:120: UserWarning: The initializer RandomNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initalizer instance more than once.\n",
      "  warnings.warn(\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "13/41 [========>.....................] - ETA: 13s - loss: 0.5874"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[101], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m em \u001b[39m=\u001b[39m embedding_labeled_latent()\n\u001b[1;32m     19\u001b[0m ae \u001b[39m=\u001b[39m autoencoder_trainer(en, de, em)\n\u001b[0;32m---> 21\u001b[0m ae\u001b[39m.\u001b[39;49mfit([X_train, y_train], X_train,\n\u001b[1;32m     22\u001b[0m        epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m,\n\u001b[1;32m     23\u001b[0m        batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m,\n\u001b[1;32m     24\u001b[0m        shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     25\u001b[0m        validation_data\u001b[39m=\u001b[39;49m([X_test, y_test], X_test))\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def autoencoder_trainer(encoder, decoder, embedding):\n",
    "\n",
    "    label = Input((1,), dtype='int32')\n",
    "    img = Input(img_size)\n",
    "\n",
    "    latent = encoder(img)\n",
    "    labeled_latent = embedding([latent, label])\n",
    "    rec_img = decoder(labeled_latent)\n",
    "    model = Model([img, label], rec_img)\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mae')\n",
    "    return model\n",
    "\n",
    "# Train Autoencoder\n",
    "n_classes = 2\n",
    "en = encoder()\n",
    "de = decoder()\n",
    "em = embedding_labeled_latent()\n",
    "ae = autoencoder_trainer(en, de, em)\n",
    "\n",
    "ae.fit([X_train, y_train], X_train,\n",
    "       epochs=30,\n",
    "       batch_size=128,\n",
    "       shuffle=True,\n",
    "       validation_data=([X_test, y_test], X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_cwgan():\n",
    "    # weight initialization\n",
    "    init = RandomNormal(stddev=0.02)\n",
    "\n",
    "    img = Input(img_size)\n",
    "    label = Input((1,), dtype='int32')\n",
    "\n",
    "\n",
    "    x = Conv2D(64, kernel_size=(4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(img)\n",
    "    # x = LayerNormalization()(x) # It is not suggested to use BN in Discriminator of WGAN\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (4, 4), strides=(2, 2), padding='same', kernel_initializer=init)(x)\n",
    "    # x = LayerNormalization()(x)\n",
    "    x = LeakyReLU(0.2)(x)\n",
    "    # x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    le = Flatten()(Embedding(n_classes, 512)(label))\n",
    "    le = Dense(4 * 4 * 256)(le)\n",
    "    le = LeakyReLU(0.2)(le)\n",
    "    x_y = multiply([x, le])\n",
    "    x_y = Dense(512)(x_y)\n",
    "\n",
    "    out = Dense(1)(x_y)\n",
    "\n",
    "    model = Model(inputs=[img, label], outputs=out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BAGAN_GP(Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        discriminator,\n",
    "        generator,\n",
    "        latent_dim,\n",
    "        discriminator_extra_steps=3,\n",
    "        gp_weight=10.0,\n",
    "    ):\n",
    "        super(BAGAN_GP, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "        self.train_ratio = trainRatio\n",
    "        self.gp_weight = gp_weight\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer, d_loss_fn, g_loss_fn):\n",
    "        super(BAGAN_GP, self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_fn = d_loss_fn\n",
    "        self.g_loss_fn = g_loss_fn\n",
    "\n",
    "    def gradient_penalty(self, batch_size, real_images, fake_images, labels):\n",
    "        \"\"\" Calculates the gradient penalty.\n",
    "\n",
    "        This loss is calculated on an interpolated image\n",
    "        and added to the discriminator loss.\n",
    "        \"\"\"\n",
    "        # get the interplated image\n",
    "        alpha = tf.random.normal([batch_size, 1, 1, 1], 0.0, 1.0)\n",
    "        diff = fake_images - real_images\n",
    "        interpolated = real_images + alpha * diff\n",
    "\n",
    "        with tf.GradientTape() as gp_tape:\n",
    "            gp_tape.watch(interpolated)\n",
    "            # 1. Get the discriminator output for this interpolated image.\n",
    "            pred = self.discriminator([interpolated, labels], training=True)\n",
    "\n",
    "        # 2. Calculate the gradients w.r.t to this interpolated image.\n",
    "        grads = gp_tape.gradient(pred, [interpolated])[0]\n",
    "        # 3. Calcuate the norm of the gradients\n",
    "        norm = tf.sqrt(tf.reduce_sum(tf.square(grads), axis=[1, 2, 3]))\n",
    "        gp = tf.reduce_mean((norm - 1.0) ** 2)\n",
    "        return gp\n",
    "\n",
    "    def train_step(self, data):\n",
    "        if isinstance(data, tuple):\n",
    "            real_images = data[0]\n",
    "            labels = data[1]\n",
    "\n",
    "        # Get the batch size\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "\n",
    "        ########################### Train the Discriminator ###########################\n",
    "        # For each batch, we are going to perform cwgan-like process\n",
    "        for i in range(self.train_ratio):\n",
    "            # Get the latent vector\n",
    "            random_latent_vectors = tf.random.normal(\n",
    "                shape=(batch_size, self.latent_dim)\n",
    "            )\n",
    "            fake_labels = tf.random.uniform((batch_size,), 0, n_classes)\n",
    "            wrong_labels = tf.random.uniform((batch_size,), 0, n_classes)\n",
    "            with tf.GradientTape() as tape:\n",
    "                # Generate fake images from the latent vector\n",
    "                fake_images = self.generator([random_latent_vectors, fake_labels], training=True)\n",
    "                # Get the logits for the fake images\n",
    "                fake_logits = self.discriminator([fake_images, fake_labels], training=True)\n",
    "                # Get the logits for real images\n",
    "                real_logits = self.discriminator([real_images, labels], training=True)\n",
    "                # Get the logits for wrong label classification\n",
    "                wrong_label_logits = self.discriminator([real_images, wrong_labels], training=True)\n",
    "\n",
    "                # Calculate discriminator loss using fake and real logits\n",
    "                d_cost = self.d_loss_fn(real_logits=real_logits, fake_logits=fake_logits,\n",
    "                                        wrong_label_logits=wrong_label_logits\n",
    "                                        )\n",
    "\n",
    "                # Calculate the gradient penalty\n",
    "                gp = self.gradient_penalty(batch_size, real_images, fake_images, labels)\n",
    "                # Add the gradient penalty to the original discriminator loss\n",
    "                d_loss = d_cost + gp * self.gp_weight\n",
    "\n",
    "            # Get the gradients w.r.t the discriminator loss\n",
    "            d_gradient = tape.gradient(d_loss, self.discriminator.trainable_variables)\n",
    "            # Update the weights of the discriminator using the discriminator optimizer\n",
    "            self.d_optimizer.apply_gradients(\n",
    "                zip(d_gradient, self.discriminator.trainable_variables)\n",
    "            )\n",
    "\n",
    "        ########################### Train the Generator ###########################\n",
    "        # Get the latent vector\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "        fake_labels = tf.random.uniform((batch_size,), 0, n_classes)\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Generate fake images using the generator\n",
    "            generated_images = self.generator([random_latent_vectors, fake_labels], training=True)\n",
    "            # Get the discriminator logits for fake images\n",
    "            gen_img_logits = self.discriminator([generated_images, fake_labels], training=True)\n",
    "            # Calculate the generator loss\n",
    "            g_loss = self.g_loss_fn(gen_img_logits)\n",
    "\n",
    "        # Get the gradients w.r.t the generator loss\n",
    "        gen_gradient = tape.gradient(g_loss, self.generator.trainable_variables)\n",
    "        # Update the weights of the generator using the generator optimizer\n",
    "        self.g_optimizer.apply_gradients(\n",
    "            zip(gen_gradient, self.generator.trainable_variables)\n",
    "        )\n",
    "        return {\"d_loss\": d_loss, \"g_loss\": g_loss}\n",
    "\n",
    "# Optimizer for both the networks\n",
    "# learning_rate=0.0002, beta_1=0.5, beta_2=0.9 are recommended\n",
    "generator_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "discriminator_optimizer = Adam(\n",
    "    learning_rate=0.0002, beta_1=0.5, beta_2=0.9\n",
    ")\n",
    "\n",
    "\n",
    "# We refer to the DRAGAN loss function. https://github.com/kodalinaveen3/DRAGAN\n",
    "# Define the loss functions to be used for discrimiator\n",
    "# We will add the gradient penalty later to this loss function\n",
    "\n",
    "# build generator with pretrained decoder and embedding\n",
    "\n",
    "# Build discriminator with pre-trained Encoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(real_logits, fake_logits, wrong_label_logits):\n",
    "    real_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits, labels=tf.ones_like(real_logits)))\n",
    "    fake_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.zeros_like(fake_logits)))\n",
    "    wrong_label_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=wrong_label_logits, labels=tf.zeros_like(fake_logits)))\n",
    "\n",
    "    return wrong_label_loss + fake_loss + real_loss\n",
    "\n",
    "# Define the loss functions to be used for generator\n",
    "def generator_loss(fake_logits):\n",
    "    fake_loss = tf.reduce_mean(\n",
    "        tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.ones_like(fake_logits)))\n",
    "    return fake_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_label(embedding, decoder):\n",
    "    # # Embedding model needs to be trained along with GAN training\n",
    "    # embedding.trainable = False\n",
    "\n",
    "    label = Input((1,), dtype='int32')\n",
    "    latent = Input((latent_dim,))\n",
    "\n",
    "    labeled_latent = embedding([latent, label])\n",
    "    gen_img = decoder(labeled_latent)\n",
    "    model = Model([latent, label], gen_img)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(encoder):\n",
    "\n",
    "    label = Input((1,), dtype='int32')\n",
    "    img = Input(img_size)\n",
    "\n",
    "    inter_output_model = Model(inputs=encoder.input, outputs=encoder.layers[-3].output)\n",
    "    x = inter_output_model(img)\n",
    "\n",
    "    le = Flatten()(Embedding(n_classes, 512)(label))\n",
    "    le = Dense(4 * 4 * 256)(le)\n",
    "    le = LeakyReLU(0.2)(le)\n",
    "    x_y = multiply([x, le])\n",
    "    x_y = Dense(512)(x_y)\n",
    "\n",
    "    out = Dense(1)(x_y)\n",
    "\n",
    "    model = Model(inputs=[img, label], outputs=out)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_model = discriminator_cwgan()  # without initialization\n",
    "g_model = generator_label(em, de)  # initialized with Decoder and Embedding\n",
    "\n",
    "bagan_gp = BAGAN_GP(\n",
    "    discriminator=d_model,\n",
    "    generator=g_model,\n",
    "    latent_dim=latent_dim,\n",
    "    discriminator_extra_steps=3,\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "bagan_gp.compile(\n",
    "    d_optimizer=discriminator_optimizer,\n",
    "    g_optimizer=generator_optimizer,\n",
    "    g_loss_fn=generator_loss,\n",
    "    d_loss_fn=discriminator_loss,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING STEP #  1 --------------------------------------------------\n",
      "Epoch 1/2\n",
      "41/41 [==============================] - 310s 8s/step - d_loss: 2.6299 - g_loss: 1.7140\n",
      "Epoch 2/2\n",
      "41/41 [==============================] - 326s 8s/step - d_loss: 1.3701 - g_loss: 2.2225\n",
      "LEARNING STEP #  2 --------------------------------------------------\n",
      "Epoch 1/2\n",
      "14/41 [=========>....................] - ETA: 3:56 - d_loss: 1.3498 - g_loss: 2.3948"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[85], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m learning_step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(LEARNING_STEPS):\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mLEARNING STEP # \u001b[39m\u001b[39m'\u001b[39m, learning_step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m \u001b[39m*\u001b[39m \u001b[39m50\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     bagan_gp\u001b[39m.\u001b[39;49mfit(X_train, y_train, batch_size\u001b[39m=\u001b[39;49m\u001b[39m128\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/keras/engine/training.py:1685\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1677\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1678\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1679\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1682\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1683\u001b[0m ):\n\u001b[1;32m   1684\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1685\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1686\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1687\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:894\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    891\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    893\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 894\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    896\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    897\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:926\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    923\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    924\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    925\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 926\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    927\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    928\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    929\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    930\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:143\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    141\u001b[0m   (concrete_function,\n\u001b[1;32m    142\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 143\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    144\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1757\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1753\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1754\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1755\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1756\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1757\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1758\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1759\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1760\u001b[0m     args,\n\u001b[1;32m   1761\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1762\u001b[0m     executing_eagerly)\n\u001b[1;32m   1763\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:381\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    380\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    382\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    383\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    384\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    385\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    386\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    387\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    388\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    389\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    390\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    394\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Desktop/Spring23/DataMiningProject/.venv/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "d_loss_history = []\n",
    "g_loss_history = []\n",
    "LEARNING_STEPS = 100\n",
    "for learning_step in range(LEARNING_STEPS):\n",
    "    print('LEARNING STEP # ', learning_step + 1, '-' * 50)\n",
    "    bagan_gp.fit(X_train, y_train, batch_size=128, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs = ae.predict([X_test, y_test])\n",
    "n = 2\n",
    "channel = 3\n",
    "plt.figure(figsize=(2*n, 4))\n",
    "decoded_imgs = decoded_imgs*0.5 + 0.5\n",
    "x_real = X_test*0.5 + 0.5\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i+1)\n",
    "    if channel == 3:\n",
    "        plt.imshow(x_real[y_test==i][0].reshape(64, 64, channel))\n",
    "    else:\n",
    "        plt.imshow(x_real[y_test==i][0].reshape(64, 64))\n",
    "        plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + n + 1)\n",
    "    if channel == 3:\n",
    "        plt.imshow(decoded_imgs[y_test==i][0].reshape(64, 64, channel))\n",
    "    else:\n",
    "        plt.imshow(decoded_imgs[y_test==i][0].reshape(64, 64))\n",
    "        plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
